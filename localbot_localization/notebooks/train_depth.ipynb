{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did it\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime # to track the time each epoch takes\n",
    "print('did it')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# load dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3437, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-2-d8107ceac1d1>\", line 1, in <module>\n",
      "    train_dataset = torchvision.datasets.CIFAR10(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torchvision/datasets/cifar.py\", line 66, in __init__\n",
      "    self.download()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torchvision/datasets/cifar.py\", line 144, in download\n",
      "    download_and_extract_archive(self.url, self.root, filename=self.filename, md5=self.tgz_md5)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torchvision/datasets/utils.py\", line 427, in download_and_extract_archive\n",
      "    download_url(url, download_root, filename, md5)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torchvision/datasets/utils.py\", line 130, in download_url\n",
      "    url = _get_redirect_url(url, max_hops=max_redirect_hops)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torchvision/datasets/utils.py\", line 78, in _get_redirect_url\n",
      "    with urllib.request.urlopen(urllib.request.Request(url, headers=headers)) as response:\n",
      "  File \"/usr/lib/python3.8/urllib/request.py\", line 222, in urlopen\n",
      "    return opener.open(url, data, timeout)\n",
      "  File \"/usr/lib/python3.8/urllib/request.py\", line 525, in open\n",
      "    response = self._open(req, data)\n",
      "  File \"/usr/lib/python3.8/urllib/request.py\", line 542, in _open\n",
      "    result = self._call_chain(self.handle_open, protocol, protocol +\n",
      "  File \"/usr/lib/python3.8/urllib/request.py\", line 502, in _call_chain\n",
      "    result = func(*args)\n",
      "  File \"/usr/lib/python3.8/urllib/request.py\", line 1397, in https_open\n",
      "    return self.do_open(http.client.HTTPSConnection, req,\n",
      "  File \"/usr/lib/python3.8/urllib/request.py\", line 1358, in do_open\n",
      "    r = h.getresponse()\n",
      "  File \"/usr/lib/python3.8/http/client.py\", line 1348, in getresponse\n",
      "    response.begin()\n",
      "  File \"/usr/lib/python3.8/http/client.py\", line 316, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/usr/lib/python3.8/http/client.py\", line 277, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/usr/lib/python3.8/socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/usr/lib/python3.8/ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/usr/lib/python3.8/ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.8/inspect.py\", line 1515, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/lib/python3.8/inspect.py\", line 1473, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/lib/python3.8/inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/lib/python3.8/inspect.py\", line 754, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "    \u001B[0;31m[... skipping hidden 1 frame]\u001B[0m\n",
      "\u001B[0;32m<ipython-input-2-d8107ceac1d1>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m train_dataset = torchvision.datasets.CIFAR10(\n\u001B[0m\u001B[1;32m      2\u001B[0m     \u001B[0mroot\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'.'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m     \u001B[0mtrain\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/datasets/cifar.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, root, train, transform, target_transform, download)\u001B[0m\n\u001B[1;32m     65\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mdownload\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 66\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdownload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     67\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/datasets/cifar.py\u001B[0m in \u001B[0;36mdownload\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    143\u001B[0m             \u001B[0;32mreturn\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 144\u001B[0;31m         \u001B[0mdownload_and_extract_archive\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0murl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mroot\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfilename\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfilename\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmd5\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtgz_md5\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    145\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/datasets/utils.py\u001B[0m in \u001B[0;36mdownload_and_extract_archive\u001B[0;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001B[0m\n\u001B[1;32m    426\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 427\u001B[0;31m     \u001B[0mdownload_url\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0murl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdownload_root\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfilename\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmd5\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    428\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/datasets/utils.py\u001B[0m in \u001B[0;36mdownload_url\u001B[0;34m(url, root, filename, md5, max_redirect_hops)\u001B[0m\n\u001B[1;32m    129\u001B[0m         \u001B[0;31m# expand redirect chain if needed\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 130\u001B[0;31m         \u001B[0murl\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_get_redirect_url\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0murl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmax_hops\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmax_redirect_hops\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    131\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/datasets/utils.py\u001B[0m in \u001B[0;36m_get_redirect_url\u001B[0;34m(url, max_hops)\u001B[0m\n\u001B[1;32m     77\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0m_\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmax_hops\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 78\u001B[0;31m         \u001B[0;32mwith\u001B[0m \u001B[0murllib\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrequest\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0murlopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0murllib\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrequest\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mRequest\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0murl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mheaders\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mheaders\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mresponse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     79\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mresponse\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0murl\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0murl\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mresponse\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0murl\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3.8/urllib/request.py\u001B[0m in \u001B[0;36murlopen\u001B[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001B[0m\n\u001B[1;32m    221\u001B[0m         \u001B[0mopener\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_opener\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 222\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mopener\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0murl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    223\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3.8/urllib/request.py\u001B[0m in \u001B[0;36mopen\u001B[0;34m(self, fullurl, data, timeout)\u001B[0m\n\u001B[1;32m    524\u001B[0m         \u001B[0msys\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0maudit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'urllib.Request'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreq\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfull_url\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreq\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreq\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mheaders\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreq\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_method\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 525\u001B[0;31m         \u001B[0mresponse\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_open\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mreq\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    526\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3.8/urllib/request.py\u001B[0m in \u001B[0;36m_open\u001B[0;34m(self, req, data)\u001B[0m\n\u001B[1;32m    541\u001B[0m         \u001B[0mprotocol\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mreq\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtype\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 542\u001B[0;31m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001B[0m\u001B[1;32m    543\u001B[0m                                   '_open', req)\n",
      "\u001B[0;32m/usr/lib/python3.8/urllib/request.py\u001B[0m in \u001B[0;36m_call_chain\u001B[0;34m(self, chain, kind, meth_name, *args)\u001B[0m\n\u001B[1;32m    501\u001B[0m             \u001B[0mfunc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhandler\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmeth_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 502\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    503\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mresult\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3.8/urllib/request.py\u001B[0m in \u001B[0;36mhttps_open\u001B[0;34m(self, req)\u001B[0m\n\u001B[1;32m   1396\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mhttps_open\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreq\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1397\u001B[0;31m             return self.do_open(http.client.HTTPSConnection, req,\n\u001B[0m\u001B[1;32m   1398\u001B[0m                 context=self._context, check_hostname=self._check_hostname)\n",
      "\u001B[0;32m/usr/lib/python3.8/urllib/request.py\u001B[0m in \u001B[0;36mdo_open\u001B[0;34m(self, http_class, req, **http_conn_args)\u001B[0m\n\u001B[1;32m   1357\u001B[0m                 \u001B[0;32mraise\u001B[0m \u001B[0mURLError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0merr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1358\u001B[0;31m             \u001B[0mr\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mh\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgetresponse\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1359\u001B[0m         \u001B[0;32mexcept\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3.8/http/client.py\u001B[0m in \u001B[0;36mgetresponse\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1347\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1348\u001B[0;31m                 \u001B[0mresponse\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbegin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1349\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mConnectionError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3.8/http/client.py\u001B[0m in \u001B[0;36mbegin\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    315\u001B[0m         \u001B[0;32mwhile\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 316\u001B[0;31m             \u001B[0mversion\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstatus\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreason\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_read_status\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    317\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mstatus\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0mCONTINUE\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3.8/http/client.py\u001B[0m in \u001B[0;36m_read_status\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    276\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_read_status\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 277\u001B[0;31m         \u001B[0mline\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreadline\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_MAXLINE\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"iso-8859-1\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    278\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mline\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0m_MAXLINE\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3.8/socket.py\u001B[0m in \u001B[0;36mreadinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m    668\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 669\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_sock\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrecv_into\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mb\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    670\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3.8/ssl.py\u001B[0m in \u001B[0;36mrecv_into\u001B[0;34m(self, buffer, nbytes, flags)\u001B[0m\n\u001B[1;32m   1240\u001B[0m                   self.__class__)\n\u001B[0;32m-> 1241\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnbytes\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbuffer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1242\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3.8/ssl.py\u001B[0m in \u001B[0;36mread\u001B[0;34m(self, len, buffer)\u001B[0m\n\u001B[1;32m   1098\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mbuffer\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1099\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_sslobj\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbuffer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1100\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\u001B[0m in \u001B[0;36mshowtraceback\u001B[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001B[0m\n\u001B[1;32m   2060\u001B[0m                         \u001B[0;31m# in the engines. This should return a list of strings.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2061\u001B[0;31m                         \u001B[0mstb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_render_traceback_\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2062\u001B[0m                     \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "    \u001B[0;31m[... skipping hidden 1 frame]\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\u001B[0m in \u001B[0;36mshowtraceback\u001B[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001B[0m\n\u001B[1;32m   2061\u001B[0m                         \u001B[0mstb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_render_traceback_\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2062\u001B[0m                     \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2063\u001B[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001B[0m\u001B[1;32m   2064\u001B[0m                                             value, tb, tb_offset=tb_offset)\n\u001B[1;32m   2065\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/ultratb.py\u001B[0m in \u001B[0;36mstructured_traceback\u001B[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[1;32m   1365\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1366\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtb\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1367\u001B[0;31m         return FormattedTB.structured_traceback(\n\u001B[0m\u001B[1;32m   1368\u001B[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001B[1;32m   1369\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/ultratb.py\u001B[0m in \u001B[0;36mstructured_traceback\u001B[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[1;32m   1265\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mmode\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mverbose_modes\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1266\u001B[0m             \u001B[0;31m# Verbose modes need a full traceback\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1267\u001B[0;31m             return VerboseTB.structured_traceback(\n\u001B[0m\u001B[1;32m   1268\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0metype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtb\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtb_offset\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnumber_of_lines_of_context\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1269\u001B[0m             )\n",
      "\u001B[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/ultratb.py\u001B[0m in \u001B[0;36mstructured_traceback\u001B[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[1;32m   1122\u001B[0m         \u001B[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1123\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1124\u001B[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001B[0m\u001B[1;32m   1125\u001B[0m                                                                tb_offset)\n\u001B[1;32m   1126\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/ultratb.py\u001B[0m in \u001B[0;36mformat_exception_as_a_whole\u001B[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001B[0m\n\u001B[1;32m   1080\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1081\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1082\u001B[0;31m         \u001B[0mlast_unique\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrecursion_repeat\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfind_recursion\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0morig_etype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrecords\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1083\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1084\u001B[0m         \u001B[0mframes\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat_records\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrecords\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlast_unique\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrecursion_repeat\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/ultratb.py\u001B[0m in \u001B[0;36mfind_recursion\u001B[0;34m(etype, value, records)\u001B[0m\n\u001B[1;32m    380\u001B[0m     \u001B[0;31m# first frame (from in to out) that looks different.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    381\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mis_recursion_error\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0metype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrecords\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 382\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrecords\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    383\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    384\u001B[0m     \u001B[0;31m# Select filename, lineno, func_name to track frames with\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root = '.',\n",
    "    train = True,\n",
    "    transform=transforms.ToTensor(),\n",
    "    download= True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEHAVES DIFFERENTLY FROM MNIST!!  \n",
    "# IT RETURNS A NUMPY ARRAY\n",
    "train_dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train_dataset.data.max()  # meaning it is in 255 (bear in mind that it is only this attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train_dataset.data.shape # N,H,W,C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Instead of being stores in tensors, it is stored in a list\n",
    "train_dataset.targets # vector of 0 to 9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root = '.',\n",
    "    train = False,\n",
    "    transform=transforms.ToTensor(),\n",
    "    download = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "K = len(set(train_dataset.targets))\n",
    "print(f'number of classes: {K}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size = batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size = batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "tmp_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size = 1, shuffle=True)\n",
    "\n",
    "for x,y in tmp_loader:\n",
    "    print(x)  # it is now a tensor!\n",
    "    print(x.shape) # (1,3,32,32) --> N,C,H,W  Behind the scenes it puts the color channel before H and W\n",
    "    print(y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, K):\n",
    "        super(CNN, self).__init__()   # call the init constructor of the nn.Module. This way, we are only adding attributes.\n",
    "        \n",
    "        # In this case, we only the layers that have parameters.\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=2)  # in_channels is the number of channels of the input image (or filter)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=2) # out_channels is the number of fiters used in this layer\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(128 * 3 * 3, 1024)\n",
    "        self.fc2 = nn.Linear(1024, K)\n",
    "        \n",
    "        \n",
    "    # instead of treating the relu as modules, we can treat them as functions. We can access them via torch funtional\n",
    "    def forward(self, x):   # this is where we pass the input into the module\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = x.view(x.size(0), -1)    \n",
    "        #x.view(-1, 128*3*3) \n",
    "        x = F.dropout(x, p=0.5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, p=0.2)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### how to compute the nn.Linear(?, 512)??\n",
    "\n",
    "Following the formula:\n",
    "\n",
    "h1 = (32 + 2*0 -1 * (3 -1) -1 / 2) +1\n",
    "\n",
    "h2 = (h3 + 2*0 -1 * (3 -1) -1 / 2) +1\n",
    "\n",
    "h3 = (h2 + 2*0 -1 * (3 -1) -1 / 2) +1\n",
    "\n",
    "? = h3 * h3 * # feature maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "h1 = math.floor(((32 + 2*0 -1 * (3 -1) -1) / 2) +1)\n",
    "h2 = math.floor(((h1 + 2*0 -1 * (3 -1) -1) / 2) +1)\n",
    "h3 = math.floor(((h2 + 2*0 -1 * (3 -1) -1) / 2) +1)\n",
    "h3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# instantiate the model\n",
    "model = CNN(K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### move model to cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # if cuda is available use CUDA\n",
    "print(device)\n",
    "model.to(device)  # this transfers all the parameters of the model to the GPU!!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### batch gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def batch_gd(model, criterion, optimizer, train_loader, test_loader, epochs):\n",
    "    train_losses = np.zeros(epochs)\n",
    "    test_losses = np.zeros(epochs)\n",
    "    \n",
    "    for it in range(epochs):\n",
    "        t0 = datetime.now()\n",
    "        train_loss = []\n",
    "        for inputs, targets in train_loader:\n",
    "            # move data in gpu\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # forward pass\n",
    "            outputs = model(inputs) # inputs.shape = (N,H,W,1) \n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss.append(loss.item())\n",
    "            \n",
    "        train_loss = np.mean(train_loss)\n",
    "        test_loss = []\n",
    "        \n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_loss.append(loss.item())\n",
    "        test_loss = np.mean(test_loss)\n",
    "        \n",
    "        # save losses\n",
    "        train_losses[it] = train_loss\n",
    "        test_losses[it] = test_loss\n",
    "        \n",
    "        dt = datetime.now() - t0\n",
    "        print(f'epoch {it+1}/{epochs}, train_loss: {train_loss:.4f}, test_loss: {test_loss:.4f}, duration: {dt}')\n",
    "    \n",
    "    return train_losses, test_losses\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train_losses, test_losses = batch_gd(model, criterion, optimizer, train_loader, test_loader, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label='train loss')\n",
    "plt.plot(test_losses, label='test loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy (train and test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# accuracy\n",
    "\n",
    "n_correct = 0.\n",
    "n_total = 0.\n",
    "\n",
    "for inputs, targets in train_loader:\n",
    "    inputs, targets = inputs.to(device), targets.to(device)\n",
    "    \n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    # get prediction\n",
    "    ## torch.max returns both max and argmax\n",
    "    _, predictions = torch.max(outputs,1) # no need for the softmax!\n",
    "    # .max(outputs, 1) 1 is for the axis = 1. That is why we that the max over the columns!!\n",
    "    \n",
    "    #print(predictions.shape) #128\n",
    "    \n",
    "    #update counts\n",
    "    n_correct += (predictions == targets).sum().item()\n",
    "    # why .item()?  --> since this is all in pytorch, to bring it back to python, we have to call .item()   That obj it has other thigs, such as grads and stuffds like that\n",
    "    n_total += targets.shape[0]\n",
    "\n",
    "train_accuracy = n_correct / n_total\n",
    "\n",
    "n_correct = 0.\n",
    "n_total = 0.\n",
    "for inputs, targets in test_loader:\n",
    "    inputs, targets = inputs.to(device), targets.to(device)\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    # get prediction\n",
    "    ## torch.max returns both max and argmax\n",
    "    _, predictions = torch.max(outputs,1) # no need for the softmax!\n",
    "    # .max(outputs, 1) 1 is for the axis = 1. That is why we that the max over the columns!!\n",
    "    \n",
    "    #print(predictions.shape) #128\n",
    "    \n",
    "    #update counts\n",
    "    n_correct += (predictions == targets).sum().item()\n",
    "    # why .item()?  --> since this is all in pytorch, to bring it back to python, we have to call .item()   That obj it has other thigs, such as grads and stuffds like that\n",
    "    n_total += targets.shape[0]\n",
    "\n",
    "test_accuracy = n_correct / n_total\n",
    "\n",
    "print(f'train acc: {train_accuracy:.4f}, test acc: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize = False, title='confusion matrix', cmap = plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:,np.newaxis]\n",
    "        print('normalized confusion matrix')\n",
    "    else:\n",
    "        print('confusion matrix without normalization')\n",
    "        \n",
    "    print(cm)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap = cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation = 45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    \n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i,j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j,i, format(cm[i,j], fmt),\n",
    "                 horizontalalignment = 'center',\n",
    "                 color ='white' if cm[i,j] > thresh else 'black')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('true label')\n",
    "    plt.xlabel('predicted label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# get prediction in an array to compute confusion matrix\n",
    "\n",
    "x_test = test_dataset.data\n",
    "y_test = test_dataset.targets\n",
    "p_test = np.array([])\n",
    "\n",
    "for inputs, targets in test_loader:\n",
    "    inputs, targets = inputs.to(device), targets.to(device)\n",
    "    \n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    # get prediction\n",
    "    ## torch.max returns both max and argmax\n",
    "    _, predictions = torch.max(outputs,1) # no need for the softmax!\n",
    "    \n",
    "    p_test = np.concatenate((p_test, predictions.cpu().numpy()))  # this only works because test_loader is not random!!!!!\n",
    "\n",
    "cm = confusion_matrix(y_test, p_test)\n",
    "plot_confusion_matrix(cm, list(range(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "labels = '''airplane\n",
    "automobile\n",
    "bird\n",
    "cat\n",
    "deer\n",
    "dog\n",
    "frog\n",
    "horse\n",
    "ship\n",
    "truck'''.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "p_test = p_test.astype(np.uint8)\n",
    "misclassified_idxs = np.where(p_test!=y_test)[0]\n",
    "i = np.random.choice(misclassified_idxs) # select one of the miclassifed idxs\n",
    "plt.imshow(x_test[i].reshape(32,32,3))\n",
    "plt.title('true label: %s predicted %s' % (labels[y_test[i]], labels[p_test[i]]))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}